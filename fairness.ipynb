{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Fairness ###\n"},{"metadata":{},"cell_type":"markdown","source":"##### This exercise we explore the concepts and techniques in fairness in machine learning #####\n<b> Through this exercise one can \n    * Increase awareness of different types of biases that can occur\n    * Explore feature data to identify potential sources of biases before training the model.\n    * Evaluate model performance in subgroup rather than aggregate\n    \n    Dataset:\n      We use the Adult census Income dataset commonly used in machine learning.\n    \n    Task is to predict if the person makes over $50,000 a year while performing different methodologies to ensure fairness\n</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"### setup\n\n%tensorflow_version 2.x\nfrom __future__ import absolute_import, division, print_function, unicode_literals","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## title Import revelant modules and install Facets\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom matplotlib import pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sns\n\n# adjust the granularity of reporting. \npd.options.display.max_rows = 10\npd.options.display.float_format = \"{:.1f}\".format\n\nfrom google.colab import widgets\n# code for facets\nfrom IPython.core.display import display, HTML\nimport base64\n!pip install facets-overview==1.0.0\nfrom facets_overview.feature_statistics_generator import FeatureStatisticsGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## load the adult data set.\n\nCOLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n           \"income_bracket\"]\n\ntrain_csv = tf.keras.utils.get_file('adult.data', \n  'https://download.mlcc.google.com/mledu-datasets/adult_census_train.csv')\ntest_csv = tf.keras.utils.get_file('adult.data', \n  'https://download.mlcc.google.com/mledu-datasets/adult_census_test.csv')\n\ntrain_df = pd.read_csv(train_csv, names=COLUMNS, sep=r'\\s*,\\s*', \n                       engine='python', na_values=\"?\")\ntest_df = pd.read_csv(test_csv, names=COLUMNS, sep=r'\\s*,\\s*', skiprows=[0],\n                      engine='python', na_values=\"?\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Analysing the dataset with facets \n    We analyse the dataset to identify any peculiarities before we train the model\n    \n    Here are some of the questions to ask before we can go ahead with the training\n        * Are there missing feature values for a large number of observations?\n        * Are there features that are missing that might affect other features?\n        * Are there any unexpected feature values?\n        * What signs of data skew do you see?\n</b>"},{"metadata":{},"cell_type":"markdown","source":"<b> We use the Facets overview to analyze the distribution of values across the Adult dataset </b> "},{"metadata":{"trusted":true},"cell_type":"code","source":"## title Visualize the Data in Facets\nfsg = FeatureStatisticsGenerator()\ndataframes = [{'table': train_df, 'name': 'trainData'}]\ncensusProto = fsg.ProtoFromDataFrames(dataframes)\nprotostr = base64.b64encode(censusProto.SerializeToString()).decode(\"utf-8\")\n\nHTML_TEMPLATE = \"\"\"<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"></script>\n        <link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html\">\n        <facets-overview id=\"elem\"></facets-overview>\n        <script>\n          document.querySelector(\"#elem\").protoInput = \"{protostr}\";\n        </script>\"\"\"\nhtml = HTML_TEMPLATE.format(protostr=protostr)\ndisplay(HTML(html))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Task #1\n    We can perform the fairness analysis on the visualization dataset in the faucet, click on the Show Raw Data button on the histograms and categorical features to see the distribution of values, and from that try to find if there are any missing features?, features missing that can affect other features? are there any unexpected feature values? are there any skews in the dataset?\n    </b>"},{"metadata":{},"cell_type":"markdown","source":"<b> Going further, using the knowledge of the Adult datset we can now construct a neural network to predict income by using the Tensor\nflow's Keras API.</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"## first convert the pandas data frame of the adult datset to tensor flow arrays.\n\ndef pandas_to_numpy(data):\n  # Drop empty rows.\n  data = data.dropna(how=\"any\", axis=0)\n\n  # Separate DataFrame into two Numpy arrays\n  labels = np.array(data['income_bracket'] == \">50K\")\n  features = data.drop('income_bracket', axis=1)\n  features = {name:np.array(value) for name, value in features.items()}\n  \n  return features, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## map the data to columns that maps to the tensor flow using tf.feature_columns\n\n##title Create categorical feature columns\n\n# we use categorical_column_with_hash_bucket() for the occupation and native_country columns to help map\n# each feature string into an integer ID.\n# since we dont know the full range of values for this columns.\noccupation = tf.feature_column.categorical_column_with_hash_bucket(\n    \"occupation\", hash_bucket_size=1000)\nnative_country = tf.feature_column.categorical_column_with_hash_bucket(\n    \"native_country\", hash_bucket_size=1000)\n\n# since we know what the possible values for the other columns\n# we can be more explicit and use categorical_column_with_vocabulary_list()\ngender = tf.feature_column.categorical_column_with_vocabulary_list(\n    \"gender\", [\"Female\", \"Male\"])\nrace = tf.feature_column.categorical_column_with_vocabulary_list(\n    \"race\", [\n        \"White\", \"Asian-Pac-Islander\", \"Amer-Indian-Eskimo\", \"Other\", \"Black\"\n    ])\neducation = tf.feature_column.categorical_column_with_vocabulary_list(\n    \"education\", [\n        \"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n        \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n        \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n        \"Preschool\", \"12th\"\n    ])\nmarital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n    \"marital_status\", [\n        \"Married-civ-spouse\", \"Divorced\", \"Married-spouse-absent\",\n        \"Never-married\", \"Separated\", \"Married-AF-spouse\", \"Widowed\"\n    ])\nrelationship = tf.feature_column.categorical_column_with_vocabulary_list(\n    \"relationship\", [\n        \"Husband\", \"Not-in-family\", \"Wife\", \"Own-child\", \"Unmarried\",\n        \"Other-relative\"\n    ])\nworkclass = tf.feature_column.categorical_column_with_vocabulary_list(\n    \"workclass\", [\n        \"Self-emp-not-inc\", \"Private\", \"State-gov\", \"Federal-gov\",\n        \"Local-gov\", \"?\", \"Self-emp-inc\", \"Without-pay\", \"Never-worked\"\n    ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# title Create numeric feature columns\n# For Numeric features, we can just call on feature_column.numeric_column()\n# to use its raw value instead of having to create a map between value and ID.\nage = tf.feature_column.numeric_column(\"age\")\nfnlwgt = tf.feature_column.numeric_column(\"fnlwgt\")\neducation_num = tf.feature_column.numeric_column(\"education_num\")\ncapital_gain = tf.feature_column.numeric_column(\"capital_gain\")\ncapital_loss = tf.feature_column.numeric_column(\"capital_loss\")\nhours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## make age a categorical feature\nage_buckets = tf.feature_column.bucketized_column(\n    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the model features.\n\n# we define the gender as a subgroup and can be used later for special handling.\n# subgroup is a group of individuals who share a common set of characteristics.\n\n# List of variables, with special handling for gender subgroup.\nvariables = [native_country, education, occupation, workclass, \n             relationship, age_buckets]\nsubgroup_variables = [gender]\nfeature_columns = variables + subgroup_variables","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> We can now train a neural network based on the features which we derived earlier, we use a feed-forward neural network with\ntwo hidden layers.\nWe first convert our high dimensional categorical features into a real-valued vector, which we call an embedded vector.\nWe use 'gender' for filtering the test for subgroup evaluations.\n</b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"deep_columns = [\n    tf.feature_column.indicator_column(workclass),\n    tf.feature_column.indicator_column(education),\n    tf.feature_column.indicator_column(age_buckets),\n    tf.feature_column.indicator_column(relationship),\n    tf.feature_column.embedding_column(native_country, dimension=8),\n    tf.feature_column.embedding_column(occupation, dimension=8),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## define Deep Neural Net Model\n\n# Parameters from form fill-ins\nHIDDEN_UNITS_LAYER_01 = 128 #@param\nHIDDEN_UNITS_LAYER_02 = 64 #@param\nLEARNING_RATE = 0.1 #@param\nL1_REGULARIZATION_STRENGTH = 0.001 #@param\nL2_REGULARIZATION_STRENGTH = 0.001 #@param\n\nRANDOM_SEED = 512\ntf.random.set_seed(RANDOM_SEED)\n\n# List of built-in metrics that we'll need to evaluate performance.\nMETRICS = [\n  tf.keras.metrics.TruePositives(name='tp'),\n  tf.keras.metrics.FalsePositives(name='fp'),\n  tf.keras.metrics.TrueNegatives(name='tn'),\n  tf.keras.metrics.FalseNegatives(name='fn'), \n  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n  tf.keras.metrics.Precision(name='precision'),\n  tf.keras.metrics.Recall(name='recall'),\n  tf.keras.metrics.AUC(name='auc'),\n]\n\nregularizer = tf.keras.regularizers.l1_l2(\n    l1=L1_REGULARIZATION_STRENGTH, l2=L2_REGULARIZATION_STRENGTH)\n\nmodel = tf.keras.Sequential([\n  layers.DenseFeatures(deep_columns),\n  layers.Dense(\n      HIDDEN_UNITS_LAYER_01, activation='relu', kernel_regularizer=regularizer),\n  layers.Dense(\n      HIDDEN_UNITS_LAYER_02, activation='relu', kernel_regularizer=regularizer),\n  layers.Dense(\n      1, activation='sigmoid', kernel_regularizer=regularizer)\n])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adagrad(LEARNING_RATE),  \n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=METRICS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## title Fit Deep Neural Net Model to the Adult Training Dataset\n\nEPOCHS = 10\nBATCH_SIZE = 1000\n\nfeatures, labels = pandas_to_numpy(train_df)\nmodel.fit(x=features, y=labels, epochs=EPOCHS, batch_size=BATCH_SIZE)\n\n## Evaluate Deep Neural Net Performance\n\nfeatures, labels = pandas_to_numpy(test_df)\nmodel.evaluate(x=features, y=labels);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Confusion Matrix ####\n<b> A confusion matrix is a gird which evaluates a models performance with predictions vs ground truth for your model and summarizes how often the model made the correct prediction and how often it made the wrong prediction. \n    \n    Let's start by creating a binary confusion matrix for our income-prediction model—binary because our label (income_bracket) has only two possible values (<50K or >50K). We'll define an income of >50K as our positive label, and an income of <50k as our negative label.\n    \n    The matrix represents four possible states\n    * true positive: Model predicts >50K, and that is the ground truth.\n    * true negative: Model predicts <50K, and that is the ground truth.\n    * false positive: Model predicts >50K, and that contradicts reality.\n    * false negative: Model predicts <50K, and that contradicts reality."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function to Visualize and plot the Binary Confusion Matrix\ndef plot_confusion_matrix(\n    confusion_matrix, class_names, subgroup, figsize = (8,6)):\n  \n  df_cm = pd.DataFrame(\n      confusion_matrix, index=class_names, columns=class_names, \n  )\n\n  rcParams.update({\n  'font.family':'sans-serif',\n  'font.sans-serif':['Liberation Sans'],\n  })\n  \n  sns.set_context(\"notebook\", font_scale=1.25)\n\n  fig = plt.figure(figsize=figsize)\n\n  plt.title('Confusion Matrix for Performance Across ' + subgroup)\n\n  # Combine the instance (numercial value) with its description\n  strings = np.asarray([['True Positives', 'False Negatives'],\n                        ['False Positives', 'True Negatives']])\n  labels = (np.asarray(\n      [\"{0:g}\\n{1}\".format(value, string) for string, value in zip(\n          strings.flatten(), confusion_matrix.flatten())])).reshape(2, 2)\n\n  heatmap = sns.heatmap(df_cm, annot=labels, fmt=\"\", \n      linewidths=2.0, cmap=sns.color_palette(\"GnBu_d\"));\n  heatmap.yaxis.set_ticklabels(\n      heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n  heatmap.xaxis.set_ticklabels(\n      heatmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n  plt.ylabel('References')\n  plt.xlabel('Predictions')\n  return fig","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}